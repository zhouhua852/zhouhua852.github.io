<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/myavatar-apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/myavatar32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/myavatar16x16.png">
  <link rel="mask-icon" href="/images/myavatar-logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://chouzz.ml').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":true,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="你只需努力，剩下的交给时间">
<meta property="og:type" content="website">
<meta property="og:title" content="Chouzz的博客">
<meta property="og:url" content="http://chouzz.ml/page/2/index.html">
<meta property="og:site_name" content="Chouzz的博客">
<meta property="og:description" content="你只需努力，剩下的交给时间">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Chouzz">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://chouzz.ml/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Chouzz的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chouzz的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">blog</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">19</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">22</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">8</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/LeetCode23-%E5%90%88%E5%B9%B6K%E4%B8%AA%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/LeetCode23-%E5%90%88%E5%B9%B6K%E4%B8%AA%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8/" class="post-title-link" itemprop="url">LeetCode23 合并K个排序链表</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-30 23:28:09" itemprop="dateCreated datePublished" datetime="2020-01-30T23:28:09+08:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-06 17:41:49" itemprop="dateModified" datetime="2020-12-06T17:41:49+08:00">2020-12-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。</p>
<p>示例:</p>
<blockquote>
<p>输入:<br>[<br>  1-&gt;4-&gt;5,<br>  1-&gt;3-&gt;4,<br>  2-&gt;6<br>]<br>输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6</p>
</blockquote>
<p>有了上一个例子21的思路，这个题目就好做了，只需要设置一个头结点，然后三个互相比较不断的调整头结点的指向即可。<br>后面又想了想，这样做有点不太好实现，可以把每个list的节点push到同一个vector中，比较提取出最小的值，然后一一保存，最后链接这些值。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ListNode* <span class="title">mergeKLists</span><span class="params">(<span class="built_in">vector</span>&lt;ListNode*&gt;&amp; lists)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> len = lists.<span class="built_in">size</span>();</span><br><span class="line">	<span class="keyword">if</span> (len ==<span class="number">1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> lists[<span class="number">0</span>];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (len ==<span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">vector</span>&lt;ListNode*&gt; resultSet;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;len;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		ListNode* head = lists[i];</span><br><span class="line">		<span class="keyword">while</span> (head!=<span class="literal">NULL</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			resultSet.push_back(head);</span><br><span class="line">			head = head-&gt;next;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">std</span>::sort(resultSet.<span class="built_in">begin</span>(),resultSet.<span class="built_in">end</span>(),cmp);</span><br><span class="line">	resultSet.push_back(<span class="literal">NULL</span>);</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;resultSet.<span class="built_in">size</span>()<span class="number">-1</span>;j++)</span><br><span class="line">	&#123;</span><br><span class="line">		resultSet[j]-&gt;next = resultSet[j + <span class="number">1</span>];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> resultSet[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cmp</span><span class="params">(<span class="keyword">const</span> ListNode* a, <span class="keyword">const</span> ListNode* b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (a-&gt;val &lt; b-&gt;val)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>写出来了，但是无法通过测试，会报错。<br>故直接看答案改写另一种方法。<br>答案使用分治归并的思想解答。<br>最终代码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ListNode* <span class="title">mergeKLists</span><span class="params">(<span class="built_in">vector</span>&lt;ListNode*&gt;&amp; lists)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> len = lists.<span class="built_in">size</span>();</span><br><span class="line">	<span class="keyword">if</span> (len == <span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (len == <span class="number">1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> lists[<span class="number">0</span>];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (len == <span class="number">2</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> mergeTwoLists(lists[<span class="number">0</span>], lists[<span class="number">1</span>]);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">int</span> mid = len / <span class="number">2</span>;</span><br><span class="line">	<span class="built_in">vector</span>&lt;ListNode*&gt; sub1_lists;</span><br><span class="line">	<span class="built_in">vector</span>&lt;ListNode*&gt; sub2_lists;</span><br><span class="line">	<span class="keyword">int</span> i;</span><br><span class="line">	<span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;mid;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		sub1_lists.push_back(lists[i]);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> j = i;j&lt;len;j++)</span><br><span class="line">	&#123;</span><br><span class="line">		sub2_lists.push_back(lists[j]);</span><br><span class="line">	&#125;</span><br><span class="line">	ListNode* l1 = mergeKLists(sub1_lists);</span><br><span class="line">	ListNode* l2 = mergeKLists(sub2_lists);</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">return</span> mergeTwoLists(l1, l2);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">ListNode* <span class="title">mergeTwoLists</span><span class="params">(ListNode* l1, ListNode* l2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (l1==<span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> l2;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (l2 ==<span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> l1;</span><br><span class="line">	&#125;</span><br><span class="line">	ListNode* p;</span><br><span class="line">	ListNode* head = p;</span><br><span class="line">	<span class="keyword">while</span> (l1 !=<span class="literal">NULL</span> &amp;&amp; l2 != <span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (l1-&gt;val&lt;l2-&gt;val)</span><br><span class="line">		&#123;</span><br><span class="line">			head-&gt;next = l1;</span><br><span class="line">			head = l1;</span><br><span class="line">			l1 = l1-&gt;next;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			head-&gt;next = l2;</span><br><span class="line">			head = l2;</span><br><span class="line">			l2 = l2-&gt;next;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (l1==<span class="literal">NULL</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			head-&gt;next = l2;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (l2 == <span class="literal">NULL</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			head-&gt;next = l1;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/Leetcode32-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/Leetcode32-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/" class="post-title-link" itemprop="url">Leetcode32 合并两个有序链表</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-30 23:26:48" itemprop="dateCreated datePublished" datetime="2020-01-30T23:26:48+08:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-06 17:41:46" itemprop="dateModified" datetime="2020-12-06T17:41:46+08:00">2020-12-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。<br>示例：</p>
<blockquote>
<p>输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4<br>输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4</p>
</blockquote>
<p>我的思路，这个题目要是不是可以用最简单的方式解决呢？假设两个链表的长度相等。那么遍历链表l1,然后依次让l2插入到l1后面。<br>但是之后发现，题目中有可能是长度不一样的，那么我就更改为如果l2比l1长，那么就从l1插入到l2，反之亦然。但是例子中又有l1或l2为空的情况，我又设置为l1为空就返回l2,反之亦然。<br>但是我在这里卡住了。</p>
<blockquote>
<p>输入<br>[5]<br>[1,2,4]<br>输出<br>[1,5,2,4]<br>预期结果<br>[1,2,4,5]</p>
</blockquote>
<p>这里明显l2比l1长，那么应该讲l1插入到l2中，最终结果应该是1,5,2,4，后面认真审题后发现，题目为讲两个有序链表合并为一个新的有序链表并返回。也就是说，</p>
<ol>
<li>输入的两个链表都是有序的，而且输入的链表可能为0；</li>
<li>输出的链表也是有序的，而且是通过输入链表组合而得到的。<br>重新整理一下思路，首先对边界进行限制，即考虑l1和l2为null的情况，然后将l1中的元素插入到l2中去。</li>
</ol>
<p>写了一段时间，不会，直接看答案吧，<br>有2中解法，我使用了迭代的方法，成功了，<strong>唯一需要注意的是最后一个元素需要单独添加。</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ListNode* <span class="title">mergeTwoLists</span><span class="params">(ListNode* l1, ListNode* l2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (l1==<span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> l2;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (l2 == <span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> l1;</span><br><span class="line">	&#125;</span><br><span class="line">	ListNode* p1 = l1;</span><br><span class="line">	ListNode* p2 = l2;</span><br><span class="line">	ListNode* head = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">	ListNode* p = head;</span><br><span class="line">	<span class="comment">//迭代方法</span></span><br><span class="line">	<span class="keyword">while</span> ( p2!=<span class="literal">NULL</span> &amp;&amp; p1!=<span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (p1-&gt;val &lt; p2-&gt;val)</span><br><span class="line">		&#123;</span><br><span class="line">			p-&gt;next = p1;</span><br><span class="line">			p1 = p1-&gt;next;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			p-&gt;next = p2;</span><br><span class="line">			p2 = p2-&gt;next;</span><br><span class="line">		&#125;</span><br><span class="line">		p = p-&gt;next;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (p1 == <span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		p-&gt;next = p2;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (p2 == <span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		p-&gt;next = p1;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> head-&gt;next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/LeetCode138-%E9%93%BE%E8%A1%A8%E7%9A%84%E6%B7%B1%E5%BA%A6%E6%8B%B7%E8%B4%9D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/LeetCode138-%E9%93%BE%E8%A1%A8%E7%9A%84%E6%B7%B1%E5%BA%A6%E6%8B%B7%E8%B4%9D/" class="post-title-link" itemprop="url">LeetCode138 链表的深度拷贝</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-30 23:22:27" itemprop="dateCreated datePublished" datetime="2020-01-30T23:22:27+08:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-06 17:41:41" itemprop="dateModified" datetime="2020-12-06T17:41:41+08:00">2020-12-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给定一个链表，每个节点包含一个额外增加的随机指针，该指针可以指向链表中的任何节点或空节点。<br>要求返回这个链表的深拷贝。<br>示例：<br><img src="https://img-blog.csdnimg.cn/2019060119344799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<pre><code>输入：
{&quot;$id&quot;:&quot;1&quot;,&quot;next&quot;:{&quot;$id&quot;:&quot;2&quot;,&quot;next&quot;:null,&quot;random&quot;:{&quot;$ref&quot;:&quot;2&quot;},&quot;val&quot;:2},&quot;random&quot;:{&quot;$ref&quot;:&quot;2&quot;},&quot;val&quot;:1}
解释：
节点 1 的值是 1，它的下一个指针和随机指针都指向节点 2 。
节点 2 的值是 2，它的下一个指针指向 null，随机指针指向它自己。</code></pre><p>这个题目有一定难度的，难度在于随机指针。这个指针域该怎么复制是一个很重要的问题。<br><strong>深度拷贝</strong>：原链表和新链表不互相影响，可以随意更改。<br>这个题目可以用map来计算，主要是存储随机指针之间的逻辑关系，map中存储的是地址和节点ID的映射。<br>难点有两点：<br>1.随机指针指向了哪一个节点？<br>2.这个节点的地址是多少？<br>而用map就是为了解决这两点的。</p>
<p>我自己的思路：首先存储随机指针指向的ID，然后新建新的指针，顺便保存值和指针以及随机指针三个参数，返回新的指针。</p>
<p>写代码发现行不通，不知道该怎么写，存储随机指针以及保存其他的指针都好写，但是怎么新建新指针和将新指针的next域、random域和原来的联系起来，这里不知道怎么写。</p>
<p>这里我的思路是有问题的，原因是我没有想清楚该做什么。我的思路是保存随机指针指向的ID，这一步保存ID是对的，但是随机指针不对，这里保存的应该是新链表中的指针，而不是旧链表，同理，新建新的指针时，值可以保存，但是next指针和随机指针不能一次性保存的。</p>
<p>正确的方法，应该是，根据原链表的长度建立新链表，仅仅将值域的值赋值，next域和random域暂时不用管，并且将新节点存放到vector中，然后保存旧节点的地址对应的id。</p>
<p>然后再次遍历旧节点，连接新节点的next域，然后由于map中保存的是旧节点的地址，所以对旧节点的random域取地址，该地址一定在map中，且对应的key值即为指向的id，结合该id在vector中索引，即可得到新节点中的random指针的地址。<br>最终代码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Node* <span class="title">copyRandomList</span><span class="params">(Node* head)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">map</span>&lt;Node*, <span class="keyword">int</span> &gt; node_map;</span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Node*&gt; node_vec;</span><br><span class="line">	Node* ptr = head;</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span> (ptr)</span><br><span class="line">	&#123;</span><br><span class="line">		node_vec.push_back(<span class="keyword">new</span> Node(ptr-&gt;val));</span><br><span class="line">		<span class="comment">//记录ptr 和ID的映射</span></span><br><span class="line">		node_map[ptr] = i++;</span><br><span class="line">		ptr = ptr-&gt;next;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	node_vec.push_back(<span class="number">0</span>);</span><br><span class="line">	ptr = head;</span><br><span class="line">	i = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span> (ptr)</span><br><span class="line">	&#123;</span><br><span class="line">		node_vec[i]-&gt;next = node_vec[i + <span class="number">1</span>];</span><br><span class="line">		<span class="keyword">if</span> (ptr-&gt;<span class="built_in">random</span>!=<span class="literal">NULL</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">int</span> id = node_map[ptr-&gt;<span class="built_in">random</span>];<span class="comment">//get ID</span></span><br><span class="line">			node_vec[i]-&gt;<span class="built_in">random</span> = node_vec[id];</span><br><span class="line">		&#125;</span><br><span class="line">		ptr = ptr-&gt;next;</span><br><span class="line">		i++;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> node_vec[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/LeetCode86-%E5%88%86%E5%89%B2%E9%93%BE%E8%A1%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/LeetCode86-%E5%88%86%E5%89%B2%E9%93%BE%E8%A1%A8/" class="post-title-link" itemprop="url">LeetCode86 分割链表</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-30 23:20:47" itemprop="dateCreated datePublished" datetime="2020-01-30T23:20:47+08:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-06 17:41:43" itemprop="dateModified" datetime="2020-12-06T17:41:43+08:00">2020-12-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构与算法</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><a href="#题目">题目</a><ul>
<li><a href="#思路">思路</a></li>
</ul>
</li>
</ul>
<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>给定一个链表和一个特定值 x，对链表进行分隔，使得所有小于 x 的节点都在大于或等于 x 的节点之前。</p>
<p>你应当保留两个分区中每个节点的初始相对位置。</p>
<p>输入: head = 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;2, x = 3<br>输出: 1-&gt;2-&gt;2-&gt;4-&gt;3-&gt;5</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>这个题目，先开始是我的思路错误，虽然我知道这个题目需要设置临时头结点，但是由于审题不清，我最先开始是想设置一个临时的结点tempnode，然后小于x就插入tempnode之前，大于或等于x就插入tempnode之后，但是当我看完相关的视频之后，发现题目的要求并不是这样的，因为题目是要求保持相对位置，而如果像我那样插入就会出现这样的情况：<br>1-&gt;2-&gt;2-&gt;tempnode-&gt;5-&gt;3-&gt;4<br>这样的结果就和题目要求的相反，看过正确答案后，不得不承认这个题目非常简单，只需要设置两个头结点，temp_less和temp_more，将小于x的值插入temp_less后面，将大于或者等于x的值插入到temp_more后面，然后将temp_less和temp_more链接起来，并将temp_more的next指针赋值为NULL，最后返回temp_less-&gt;next即可。</p>
<p>中间出现时间超过限制的错误，最后发现不断有输出数据跳出来，检查发现，temp_more的指针没有赋值为NULL，故不断循环下去。<br>另外注意的是链接两个链表时要连接头结点！！！而temp_less和temp_more不在是头结点了。<br>最终代码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//技巧在于巧用临时头结点</span></span><br><span class="line">	<span class="function">ListNode <span class="title">less_head</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line">	<span class="function">ListNode <span class="title">more_head</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line">	ListNode* tempnode_less = &amp;less_head;</span><br><span class="line">	ListNode* tempnode_more = &amp;more_head;</span><br><span class="line">	ListNode* result = head;</span><br><span class="line">	<span class="comment">//if head is not NULL</span></span><br><span class="line">	<span class="keyword">while</span> (head)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">//save head 's next</span></span><br><span class="line">		ListNode* next = head-&gt;next;</span><br><span class="line"> </span><br><span class="line">		<span class="keyword">if</span> (head-&gt;val &lt;x)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//create less x list node</span></span><br><span class="line">			tempnode_less-&gt;next = head;</span><br><span class="line">			tempnode_less = head;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//create more x list node</span></span><br><span class="line">			tempnode_more-&gt;next = head;</span><br><span class="line">			tempnode_more = head;</span><br><span class="line">		&#125;</span><br><span class="line"> </span><br><span class="line">		<span class="comment">//begin next node</span></span><br><span class="line">		head = next;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//connect list node, care of "more_head.next"</span></span><br><span class="line">	tempnode_less-&gt;next = more_head.next;</span><br><span class="line">	tempnode_more-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">return</span> less_head.next;</span><br></pre></td></tr></table></figure>
<p>最终用时：超过一小时</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">机器学习之线性回归笔记</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-30 23:17:53" itemprop="dateCreated datePublished" datetime="2020-01-30T23:17:53+08:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-10 21:44:14" itemprop="dateModified" datetime="2021-06-10T21:44:14+08:00">2021-06-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>平台</strong>：windows10 64位<br><strong>IDE</strong>：Pycharm<br><strong>Python版本</strong>：Python3.5<br><strong>github代码</strong>：<a href="https://github.com/chouzz/machine-learning/tree/master/my_lineRegression" target="_blank" rel="noopener">源代码</a></p>
<hr>
<h1 id="1-目录"><a href="#1-目录" class="headerlink" title="1 目录"></a>1 目录</h1><ul>
<li><a href="#1-目录">1 目录</a></li>
<li><a href="#2-回归的理解">2 回归的理解</a></li>
<li><a href="#3-线性回归">3 线性回归</a></li>
<li><a href="#4-使用最大似然解释最小二乘">4 使用最大似然解释最小二乘</a><ul>
<li><a href="#41-基本形式">4.1 基本形式</a></li>
<li><a href="#42-高斯的对数似然与最小二乘">4.2 高斯的对数似然与最小二乘</a></li>
<li><a href="#43-向量表示下的求解">4.3 向量表示下的求解</a></li>
<li><a href="#44-l2正则化math-xmlnshttpwwww3org1998mathmathmlsemanticsmrowmi-mathvariantnormalℓmimn2mnmomominmimiomimirmimimmimrowannotation-encodingapplicationx-texell2-normannotationsemanticsmathℓ2norm">4.4 L2正则化($\ell2-norm$)</a></li>
<li><a href="#45-l1正则化math-xmlnshttpwwww3org1998mathmathmlsemanticsmrowmi-mathvariantnormalℓmimn1mnmomominmimiomimirmimimmimrowannotation-encodingapplicationx-texell1-normannotationsemanticsmathℓ1norm">4.5 L1正则化($\ell1-norm$)</a></li>
<li><a href="#46-lastic-net">4.6 lastic Net</a></li>
<li><a href="#47-l1和l2正则的区别">4.7 L1和L2正则的区别</a></li>
</ul>
</li>
<li><a href="#5-梯度下降法">5 梯度下降法</a></li>
<li><a href="#6-程序分析">6 程序分析</a></li>
<li><a href="#7-分析sklearn线性回归的官方例程">7 分析sklearn线性回归的官方例程</a><ul>
<li><a href="#71-官方例程分析">7.1 官方例程分析</a></li>
<li><a href="#72-使用sklearn方法训练自己生成的数据">7.2 使用sklearn方法训练自己生成的数据</a></li>
</ul>
</li>
<li><a href="#8-参考书目">8 参考书目</a></li>
</ul>
<h1 id="2-回归的理解"><a href="#2-回归的理解" class="headerlink" title="2 回归的理解"></a>2 回归的理解</h1><p>回归是由高尔顿最先在生物遗传上提出的，在线性回归中，与其说其为回归，不如说线性拟合更合适，而为了纪念高尔顿还是保留了回归这一名词<br>而<strong>对数几率回归（Logistic regression）</strong>解决的却是一个<strong>分类</strong>问题，其实就是2分类，如果需要解决多分类那么就做多次2分类或直接用<strong>Softmax回归</strong>。</p>
<h1 id="3-线性回归"><a href="#3-线性回归" class="headerlink" title="3 线性回归"></a>3 线性回归</h1><p>线性回归试图建立的一个线性模型以尽可能准确的预测输出标记。考虑最简单的模型，给定若干对$(x,y)$的数据，将其在坐标轴上表示如下：</p>
<center>![散点图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNDIyMjYxOTQ1Mj93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png)

<p>线性回归就是要寻找一条直线来使得这些所有的点都尽量符合直线上的点，其中尽量符合指的就是使损失最小，在这里以点到直线的距离的平方来作为‘损失’，使用线性回归可以来预测数据，这在机器学习里面是一个非常重要的概念——预测，不管是什么模型，最后做出来都是需要用来预测数据，来判断这个模型到底实不实用，线性回归就是这些模型中最简单的一种模型。</p>
<center>![线性回归图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNDIyMjY1MDM4Mj93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png)

<h1 id="4-使用最大似然解释最小二乘"><a href="#4-使用最大似然解释最小二乘" class="headerlink" title="4 使用最大似然解释最小二乘"></a>4 使用最大似然解释最小二乘</h1><h2 id="4-1-基本形式"><a href="#4-1-基本形式" class="headerlink" title="4.1 基本形式"></a>4.1 基本形式</h2><p>首先对于线性回归，所求得就是一条直线，设其方程为：<br>$$y^{(i)}=\theta^Tx^{(i)}+\varepsilon^{(i)}$$<br>其中$\theta$和$\varepsilon$为这条直线的斜率和截距，$x,y$分别为图上的一系列散点，用极大似然法估计时，我们认为$\varepsilon$符合正太分布，且期望为0，那么根据大学的知识可以得到$\varepsilon$的概率为：<br>$$p(\varepsilon^{(i)})=\frac{1}{s\sqrt{2\pi\sigma}}exp(-\frac{(\varepsilon^{(i)})^2}{2\sigma^2})$$<br>把直线方程移项带入上式得到在$\theta$参数下，已知$x$的情况下$y$的概率密度函数为：<br>$$p(y^{(i)}|x^{(i)};\theta)=\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})$$<br>这里的概率密度函数为条件概率密度函数，直接求解是无法解出来的，假设样本之间是独立的，那么就得到：</p>
<p>\begin{aligned}<br>L(\theta)&amp;=\coprod_{i=1}^m p(y^{(i)}|x^{(i)};\theta)\&amp;=\coprod_{i=1}^m\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})<br>\end{aligned}</p>
<h2 id="4-2-高斯的对数似然与最小二乘"><a href="#4-2-高斯的对数似然与最小二乘" class="headerlink" title="4.2 高斯的对数似然与最小二乘"></a>4.2 高斯的对数似然与最小二乘</h2><p>这里用的是对数似然，即需要对$L(\theta)$取对数，则可以化简得到如下方程：<br>\begin{aligned}<br>\ell(\theta)&amp;=\log{L(\theta)}\&amp;=\log{\coprod_{i=1}^m\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})}\&amp;=\sum_{i=1}^m \log{\frac{1}{\sqrt{2\pi\sigma}}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})}\&amp;=m\log{\frac{1}{\sqrt{2\pi\sigma}}}-\frac{1}{\sigma^2}\cdot\frac{1}{2}\sum_{i=1}^m(y^{(i)}-theta^Tx^{(i)})<br>\end{aligned}<br>现在，需要求$L(\theta)$为最大值时$\theta$的值，前面一项为常数，可以省略掉，只保留后方一项得到函数：<br>$$J(\theta)=\frac{1}{2}\sum_{i=1}^m(y^{(i)}-\theta^Tx^{(i)})$$<br>即求$J(\theta)$的最小值，括号里的一项就是预测值和实际值之间的差，这个就成为目标函数或成为损失函数，这其实就是最小二乘估计，整个推导过程其实就是利用高斯分布推导最小二乘。</p>
<h2 id="4-3-向量表示下的求解"><a href="#4-3-向量表示下的求解" class="headerlink" title="4.3 向量表示下的求解"></a>4.3 向量表示下的求解</h2><p>设有$M$个$N$维样本组成矩阵$X$，即$X$的行对应每个样本，$X$的列对应样本的维度，<strong>目标函数</strong>就可以表示为：<br>$$J(\theta)=\frac{1}{2}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2=\frac{1}{2}(X\theta-y)^T(X\theta-y)$$<br>即现在要求出$J(\theta)$最小值时$\theta$的值，对目标函数求导，令其等于$0$，求出$\theta$的值。</p>
<p>\begin{aligned}<br>\nabla_\theta J(\theta) &amp;= \frac{1}{2}\sum_{i=1}^m(h_\theta x^{(i)}-y^{(i)})^2\&amp;=\nabla_\theta \left{ \frac{1}{2} (\theta^TX^TX\theta-]theta^TX^Ty-y^TX\theta+h^Ty)\right}\&amp;=\frac{1}{2}(2X^TX\theta-X^Ty-(y^TX)^T)\&amp;=X^TX\theta-x^Ty<br>\end{aligned}<br>得到最后的结果如下：<br>$$\theta=(X^TX)^{-1}X^Ty$$</p>
<h2 id="4-4-L2正则化-ell2-norm"><a href="#4-4-L2正则化-ell2-norm" class="headerlink" title="4.4 L2正则化($\ell2-norm$)"></a>4.4 L2正则化($\ell2-norm$)</h2><p>而在现实中当特征比样本点更多时，矩阵$X$不是满秩矩阵， $X^TX$不一定可逆，通常引入<strong>正则化(egularization)</strong>项，其实质是为了<strong>防止过拟合</strong>,<br>$$ \frac{1}{2}\sum_{i=1}^m(h_\theta x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^n\theta_j ^2$$<br>称为<strong>$L2$正则($\ell2-norm$)</strong>，那么加了$L2$正则的最小二乘称为<strong>岭回归</strong>，求解可得$\theta$为：<br>$$\theta=(X^TX+\lambda I)^{-1}X^Ty$$</p>
<h2 id="4-5-L1正则化-ell1-norm"><a href="#4-5-L1正则化-ell1-norm" class="headerlink" title="4.5 L1正则化($\ell1-norm$)"></a>4.5 L1正则化($\ell1-norm$)</h2><p>既然有L2正则化，那么也必然有<strong>L1正则化($\ell1-norm$)</strong>，将目标函数正则项中$\theta$的平方替换为$\theta$的绝对值，那么就叫L1正则，即<strong>LASSO</strong>。<br>$$ \frac{1}{2}\sum_{i=1}^m(h_\theta x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^n|\theta_j| $$</p>
<h2 id="4-6-lastic-Net"><a href="#4-6-lastic-Net" class="headerlink" title="4.6 lastic Net"></a>4.6 lastic Net</h2><p>结合l1和l2正则，即为Elastic Net:<br>$$ \frac{1}{2}\sum_{i=1}^m(h_\theta x^{(i)}-y^{(i)})^2+\lambda(\rho\cdot\sum_{j=1}^n|\theta_j| +(1-\rho)\cdot\sum_{j=1}^n\theta_j ^2)$$</p>
<h2 id="4-7-L1和L2正则的区别"><a href="#4-7-L1和L2正则的区别" class="headerlink" title="4.7 L1和L2正则的区别"></a>4.7 L1和L2正则的区别</h2><p>使用绝对值取代平方和，在$\lambda$最够大时，高阶的情况下高阶项的系数会缩减到0</p>
<h1 id="5-梯度下降法"><a href="#5-梯度下降法" class="headerlink" title="5 梯度下降法"></a>5 梯度下降法</h1><p>求出目标函数了，就要根据目标函数来求的这条直线，这里常用的一种方法就是梯度下降法，梯度下降法的公式如下：<br>$$\theta=\theta-\alpha\cdot\frac{\partial J(\theta)}{\partial\theta}$$<br>其中$\alpha$表示学习率，$\theta$为参数，具体做法就是初始化$\theta$，然后沿着负梯度方向迭代，不断更新$\theta$使就$J(\theta)$最小。</p>
<h1 id="6-程序分析"><a href="#6-程序分析" class="headerlink" title="6 程序分析"></a>6 程序分析</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">6</span>, <span class="number">11</span>) + np.random.randn(<span class="number">11</span>)</span><br><span class="line">x = np.sort(x)</span><br><span class="line">y = x ** <span class="number">2</span> + <span class="number">2</span> + np.random.randn(<span class="number">11</span>)</span><br></pre></td></tr></table></figure>
<p>首先生成随机点x，y，随机生成11个点，这11个点是根据y=x2+2这条曲线上生成的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimizer</span><span class="params">()</span>:</span></span><br><span class="line">    w = <span class="number">0</span></span><br><span class="line">    b = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        w, b = compute_gradient(w, b, <span class="number">0.02</span>)</span><br><span class="line">        <span class="comment"># if i % 50 == 0:</span></span><br><span class="line">            <span class="comment"># plt.plot(x, x * w + b, 'b-')</span></span><br><span class="line">            <span class="comment"># plt.pause(0.5)</span></span><br><span class="line">    y_pre = x * w + b</span><br><span class="line">    print(w, b)</span><br><span class="line">    <span class="keyword">return</span> y_pre</span><br></pre></td></tr></table></figure>
<p>这个函数是执行梯度下降法1000次，以此来找到最优的w，b，每执行一次，都将新的w，b带入梯度中来求，最后求得最终的w，b，然后可以得到最终拟合的直线，即y_pre.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def compute_gradient(m_current, b_current, learning_rate):</span><br><span class="line">    N &#x3D; len(x)  # 数据的长度</span><br><span class="line">    m_gradient &#x3D; 0.0</span><br><span class="line">    b_gradient &#x3D; 0.0</span><br><span class="line">    for i in range(N):</span><br><span class="line">        m_gradient +&#x3D; -(2 &#x2F; N) * x[i] * (y[i] - (m_current * x[i] + b_current))</span><br><span class="line">        b_gradient +&#x3D; -(2 &#x2F; N) * (y[i] - (m_current * x[i] + b_current))</span><br><span class="line">    new_m &#x3D; m_current - (learning_rate * m_gradient)</span><br><span class="line">    new_b &#x3D; b_current - (learning_rate * b_gradient)</span><br><span class="line">    return new_m, new_b</span><br></pre></td></tr></table></figure>
<p>在compute_gradient函数中，主要是返回每次计算的$w，b$以及<br>$\frac{\partial J(\theta)}{\partial\theta}$，上面函数中for循环就是所求的偏导数，返回值是计算一次梯度下降时的$w，b$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="string">'ro'</span>)</span><br><span class="line">plt.plot(x, optimizer(), <span class="string">'b-'</span>)</span><br><span class="line"><span class="comment">#optimizer()</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>在多次计算后，再将散点图最终求得的直线图画出来即可。</p>
<h1 id="7-分析sklearn线性回归的官方例程"><a href="#7-分析sklearn线性回归的官方例程" class="headerlink" title="7 分析sklearn线性回归的官方例程"></a>7 分析sklearn线性回归的官方例程</h1><p>官方网站为：<a href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py" target="_blank" rel="noopener">Linear Regression Example</a></p>
<h2 id="7-1-官方例程分析"><a href="#7-1-官方例程分析" class="headerlink" title="7.1 官方例程分析"></a>7.1 官方例程分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br></pre></td></tr></table></figure>
<p>导入库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">diabetes &#x3D; datasets.load_diabetes()     # 导出数据集</span><br></pre></td></tr></table></figure>
<p>导出数据集，其中diabetes是<code>sklearn.datasets.base.Bunch</code>类型，该类型和Python内置的字典类型相似</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">diabetes_X &#x3D; diabetes.data[:, np.newaxis, 2]        # 分割数据集</span><br></pre></td></tr></table></figure>
<p>这个用法为sklearn中的用法，<code>datasets.data</code>为<code>dataset</code>对象中的<code>data</code>属性，而<code>data</code>属性对应的数据为一个二维数组，故<code>[:, np.newaxis,2]</code>为取data中的所有行，增加一个维度，第三列,故<code>diabetes_X</code>为一个二维数组,如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;data&#39;: array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,</span><br><span class="line">          0.01990842, -0.01764613],</span><br><span class="line">        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,</span><br><span class="line">         -0.06832974, -0.09220405],</span><br><span class="line">        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,</span><br><span class="line">          0.00286377, -0.02593034],</span><br><span class="line">        ..., </span><br><span class="line">        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,</span><br><span class="line">         -0.04687948,  0.01549073],</span><br><span class="line">        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,</span><br><span class="line">          0.04452837, -0.02593034],</span><br><span class="line">        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,</span><br><span class="line">         -0.00421986,  0.00306441]]),</span><br></pre></td></tr></table></figure>
<p>上面得到的diabetes_X的shape为(442, 1)，再将其分为训练集和测试集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">diabetes_X_train &#x3D; diabetes_X[:-20]</span><br><span class="line">diabetes_X_test &#x3D; diabetes_X[-20:]</span><br></pre></td></tr></table></figure>
<p>该句中前0个到倒数第20个分为训练集，倒数20个数据为测试集。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">diabetes_y_train &#x3D; diabetes.target[:-20]</span><br><span class="line">diabetes_y_test &#x3D; diabetes.target[-20:]</span><br></pre></td></tr></table></figure>
<p>同理，将diabetes中的target属性也这样划分。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">regr &#x3D; linear_model.LinearRegression()</span><br><span class="line">regr.fit(diabetes_X_train, diabetes_y_train)</span><br><span class="line">diabetes_y_pred &#x3D; regr.predict(diabetes_X_test)</span><br></pre></td></tr></table></figure>
<p>然后创建一个线性模型的对象，并用训练集来fit，最后得到预测的数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># The coefficients</span><br><span class="line">print(&#39;Coefficients: \n&#39;, regr.coef_)</span><br><span class="line"># The mean squared error</span><br><span class="line">print(&quot;Mean squared error: %.2f&quot;</span><br><span class="line">      % mean_squared_error(diabetes_y_test, diabetes_y_pred))</span><br><span class="line"># Explained variance score: 1 is perfect prediction</span><br><span class="line">print(&#39;Variance score: %.2f&#39; % r2_score(diabetes_y_test, diabetes_y_pred))</span><br></pre></td></tr></table></figure>
<p>打印出相关系数和均方误差以及差异分数<br>这里相关系数为$R$，回归系数为$R^2$,而回归系数<br>$$R^2=\frac{SSReg}{SST}=1-\frac{SSE}{SST}$$<br>其中$SSReg$为回归平方和（sum of squares for regression），也叫做模型平方和，，SSE为残差平方（sum of squares for error），SST为总平方和（SSReg+SSE），其中各公式如下：<br>$$SST=\sum_{i=1}^n(y_i-\bar{y})^2$$<br>$$SSReg=\sum_{i}(\hat{y_i}-\bar{y})^2$$<br>$$SSE=\sum_{i}(y_i-\hat{y})^2$$<br>故在本次实验中相关系数$R$即为：<br>$$R=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2\sum_{i=1}^n(y_i-\bar{y})^2}}$$<br>$\hat{y_i}$表示的为回归直线中$y$的值，$\bar{y}$表示$y$的平均值.最后结果如下：</p>
<center>![官方例程结果](https://img-blog.csdn.net/20180328112825821?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
## 7.2 使用sklearn方法训练自己生成的数据
代码如下：
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">6</span>, <span class="number">11</span>) + np.random.randn(<span class="number">11</span>)</span><br><span class="line">x = np.sort(x)</span><br><span class="line">y = x ** <span class="number">2</span> + <span class="number">2</span> + np.random.randn(<span class="number">11</span>)</span><br><span class="line">x=x[:,np.newaxis]</span><br><span class="line">print(x)</span><br><span class="line">regr = linear_model.LinearRegression()</span><br><span class="line">regr.fit(x,y)</span><br><span class="line">y_pre = regr.predict(x)</span><br><span class="line"></span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(x,y_pre)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
预测结果：
![sklaern预测生成数据结果](https://img-blog.csdn.net/20180328113152895?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
可以看到，使用sklearn的预测结果和使用梯度下降法的线性回归结果是一模一样的。
# 8 参考书目
- 机器学习实战 
- 机器学习 周志华
- [线性回归理解（附纯python实现）](http://blog.csdn.net/sxf1061926959/article/details/66976356?locationNum=9&fps=1) 
- [sklaern官网例程](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)</center></center></center>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">机器学习之决策树笔记</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-30 22:50:13" itemprop="dateCreated datePublished" datetime="2020-01-30T22:50:13+08:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-10 21:44:16" itemprop="dateModified" datetime="2021-06-10T21:44:16+08:00">2021-06-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><a href="#1-目录">1 目录</a></li>
<li><a href="#2-基本算法">2 基本算法</a></li>
<li><a href="#3-数据划分">3 数据划分</a></li>
<li><a href="#4-信息增益">4 信息增益</a><ul>
<li><a href="#41-信息熵">4.1 信息熵</a></li>
</ul>
</li>
<li><a href="#5-python-代码">5 Python 代码</a></li>
<li><a href="#6-参考书目">6 参考书目</a></li>
</ul>
<p><strong>平台</strong>：windows10 64 位<br><strong>IDE</strong>：Pycharm<br><strong>Python 版本</strong>：Python 3.5<br><strong>github 代码</strong>：<a href="https://github.com/chouzz/machine-learning/tree/master/practice" target="_blank" rel="noopener">源代码 my_DecisionTree.py</a></p>
<hr>
<h2 id="1-目录"><a href="#1-目录" class="headerlink" title="1 目录"></a>1 目录</h2><p><strong>决策树(decision tree)</strong>是一种常见的机器学习方法，其实在生活中我们已经用到了决策树相关的知识，比如说，女生相亲时的想法就是决策树的一种体现：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNDE5NTQzMDI2Mz93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png" alt="决策树"></p>
<p>那么对于一般女生来说，首选的就是看对方年龄，根据年龄是否超过 30 来决定见不见南方，如果超过，不见，如果没有超过就继续判断，依次类推，这就是一个决策树。那么对于上面的决策树来说，要解决的问题就是对当前男生的数据构建一颗决策树，用来对未来男生进行分类，即当要进行下一次相亲时，根据决策树来判断是否见面。一般的，一颗决策树包含一个<strong>根节点</strong>、若干个内部节点和若干个<strong>叶节点</strong>，叶节点对应决策及结果，其他节点对应于一个属性的测试。可以很轻松的理解到，上图中年龄为根节点，长相、收入、公务员为内部节点，见或不见为叶节点。</p>
<hr>
<h2 id="2-基本算法"><a href="#2-基本算法" class="headerlink" title="2 基本算法"></a>2 基本算法</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNDE5NTg0NTU5Mj93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png" alt="决策树基本算法图"></p>
<hr>
<h2 id="3-数据划分"><a href="#3-数据划分" class="headerlink" title="3 数据划分"></a>3 数据划分</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNTE0NDUzMzczND93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png" alt="weka数据集"><br>要想建立一个决策树，首先需要建立一个根节点，对于以上的数据集来说就是先根据那个类别来划分，即<em>‘outlook、temperature、humidity、windy’</em>中的哪个类别作为根节点，这就需要一个量来作为度量，那就是信息增益，以<em>信息增益</em>来作为划分依据的成为<strong>ID3（Iterative Dichotomiser 迭代二分器）</strong>算法，还有以<em>增益率（gain ratio）</em>来划分的称为<strong>C4.5 算法</strong>，以<em>基尼系数（Gini index）</em>划分的成为<strong>CART 决策树</strong>。</p>
<hr>
<h2 id="4-信息增益"><a href="#4-信息增益" class="headerlink" title="4 信息增益"></a>4 信息增益</h2><h3 id="4-1-信息熵"><a href="#4-1-信息熵" class="headerlink" title="4.1 信息熵"></a>4.1 信息熵</h3><p><strong>信息熵（information entropy）</strong>是用来度量信息源的不确定度。它的公式如下：</p>
<p>$$<br>Ent(D)=-\sum_{k=1}^{|y|}p_k\log_2p_k \tag{1}<br>$$</p>
<p>其中$p_k$为数据集$D$中的$k$类样本所占的比例，$Ent(D)$越小，则$D$的纯度越高。<br>对于 weka 数据集来说，该数据集共有 14 个样本，用来预测某一天是否合适外出游玩，那么显然这里就得$k=1,2$，即外出或不外出两种情况，外出所占比例为$\frac{9}{14}$，而不外出所占比例为$\frac{5}{14}$，根据以上公式根节点的信息增益可以计算出来为：<br>$$Ent(D)=-(\frac{9}{14}\log_2\frac{9}{14}+\frac{5}{14}\log_2\frac{5}{14}=0.94)$$<br>即为该<strong>数据集的信息熵</strong>。<br>###4.2 条件熵<br>条件熵的公式如下：<br>$$Ent(D)=-\sum_{v=1}^V\frac{|D^v|}{|D|}Ent(D^v)\tag{2}$$<br>以‘outlook’为例来计算在 outlook 条件下的信息熵，那么就要计算当前属性集合中的每个属性的信息增益，即<em>‘sunny’‘overcast’‘rainy’</em>这三个属性的每一个属性的信息增益，先来计算 sunny 属性的信息增益，将天气为<em>sunny</em>的保留，得到如下所示数据集：</p>
<table>
<thead>
<tr>
<th align="center">outlook</th>
<th align="center">temperature</th>
<th align="center">humidity</th>
<th align="center">windy</th>
<th align="center">play</th>
</tr>
</thead>
<tbody><tr>
<td align="center">sunny</td>
<td align="center">hot</td>
<td align="center">high</td>
<td align="center">FALSE</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">sunny</td>
<td align="center">hot</td>
<td align="center">high</td>
<td align="center">TRUE</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">sunny</td>
<td align="center">mild</td>
<td align="center">high</td>
<td align="center">FALSE</td>
<td align="center">no</td>
</tr>
<tr>
<td align="center">sunny</td>
<td align="center">cool</td>
<td align="center">normal</td>
<td align="center">FALSE</td>
<td align="center">yes</td>
</tr>
<tr>
<td align="center">sunny</td>
<td align="center">mild</td>
<td align="center">normal</td>
<td align="center">TRUE</td>
<td align="center">yes</td>
</tr>
</tbody></table>
<p>这里在<em>sunny</em>的情况下，外出所占比例为$\frac{2}{5}$，不外出比例为$\frac{3}{5}$，故可以计算出此时的信息熵$Ent(D^1)$，同样的情况下可以计算出<em>overcast</em>，<em>rainy</em>的信息熵$Ent(D^2)$，$Ent(D^3)$，然后<em>sunny</em>占<em>outlook</em>比例为$\frac{5}{14}$，<em>overcast</em>和<em>raniy</em>占比为$\frac{4}{14}$,$\frac{5}{14}$,那么此时的信息增益即为：</p>
<p>$Gain(D,outlook)=Ent(D)-(\frac{5}{14}Ent(D^1)+\frac{4}{14}Ent(D^2)+\frac{5}{14}Ent(D^3)$</p>
<p>这就是<em>outlook</em>属性的信息增益，同样可以计算出其他属性的信息增益，将其比较大小，找出最大值作为第一次分类的特征，即作为根节点。然后依次迭代循环，计算出整个决策树。</p>
<hr>
<h2 id="5-Python-代码"><a href="#5-Python-代码" class="headerlink" title="5 Python 代码"></a>5 Python 代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">dataSet = [[<span class="string">'sunny'</span>, <span class="string">'hot'</span>, <span class="string">'high'</span>, <span class="string">'FALSE'</span>, <span class="string">'no'</span>],</span><br><span class="line">           [<span class="string">'sunny'</span>, <span class="string">'hot'</span>, <span class="string">'high'</span>, <span class="string">'TRUE'</span>, <span class="string">'no'</span>],</span><br><span class="line">           [<span class="string">'overcast'</span>, <span class="string">'hot'</span>, <span class="string">'high'</span>, <span class="string">'FALSE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'rainy'</span>, <span class="string">'mild'</span>, <span class="string">'high'</span>, <span class="string">'FALSE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'rainy'</span>, <span class="string">'cool'</span>, <span class="string">'normal'</span>, <span class="string">'FALSE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'rainy'</span>, <span class="string">'cool'</span>, <span class="string">'normal'</span>, <span class="string">'TRUE'</span>, <span class="string">'no'</span>],</span><br><span class="line">           [<span class="string">'overcast'</span>, <span class="string">'cool'</span>, <span class="string">'normal'</span>, <span class="string">'TRUE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'sunny'</span>, <span class="string">'mild'</span>, <span class="string">'high'</span>, <span class="string">'FALSE'</span>, <span class="string">'no'</span>],</span><br><span class="line">           [<span class="string">'sunny'</span>, <span class="string">'cool'</span>, <span class="string">'normal'</span>, <span class="string">'FALSE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'rainy'</span>, <span class="string">'mild'</span>, <span class="string">'normal'</span>, <span class="string">'FALSE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'sunny'</span>, <span class="string">'mild'</span>, <span class="string">'normal'</span>, <span class="string">'TRUE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'overcast'</span>, <span class="string">'mild'</span>, <span class="string">'high'</span>, <span class="string">'TRUE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'overcast'</span>, <span class="string">'hot'</span>, <span class="string">'normal'</span>, <span class="string">'FALSE'</span>, <span class="string">'yes'</span>],</span><br><span class="line">           [<span class="string">'rainy'</span>, <span class="string">'mild'</span>, <span class="string">'high'</span>, <span class="string">'TRUE'</span>, <span class="string">'no'</span>]]</span><br><span class="line">labels = [<span class="string">'outlook'</span>,<span class="string">'temperature'</span>,<span class="string">'humidity'</span>,<span class="string">'windy'</span>,<span class="string">'play'</span>]</span><br></pre></td></tr></table></figure>

<p>首先创建数据集，以列表的方式存储。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcentropy</span><span class="params">(data)</span>:</span></span><br><span class="line">    numentropy = len(data)</span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> data:  <span class="comment"># 数据集的每一行</span></span><br><span class="line">        currentlabel = featVec[<span class="number">-1</span>]  <span class="comment"># 每一行的最后一个类别</span></span><br><span class="line">        <span class="keyword">if</span> currentlabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():  <span class="comment"># 如果当前标签不在字典的关键字中</span></span><br><span class="line">            labelCounts[currentlabel] = <span class="number">0</span>  <span class="comment"># 让当前标签为0，实际上是增加字典的关键字</span></span><br><span class="line">        labelCounts[currentlabel] += <span class="number">1</span>  <span class="comment"># 如果在字典里，就增加1，实际上是统计每个标签出现的次数</span></span><br><span class="line">    shannonEnt = <span class="number">0</span>  <span class="comment"># 香农熵，即最后的返回结果</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:     <span class="comment"># 遍历labelCount中的每一个关键词</span></span><br><span class="line">        prob = labelCounts[key] / numentropy    <span class="comment"># 用关键词的个数除以总个数得到概率</span></span><br><span class="line">        shannonEnt -= prob * np.log2(prob)      <span class="comment"># 求信息熵，即香农熵</span></span><br><span class="line"><span class="keyword">return</span> shannonEnt</span><br></pre></td></tr></table></figure>

<p>然后创建一个函数用来计算信息熵，这个函数有个特点就是用 for 循环和字典来记录一列数据中每个属性出现的次数，然后通过出现的次数除以总次数来计算概率，最后求得信息熵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitData</span><span class="params">(data, axis, value)</span>:</span>       <span class="comment"># 划分数据集</span></span><br><span class="line">    retData = []</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> data:    <span class="comment"># 用featVec表示每一个样本</span></span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:      <span class="comment"># 如果value的值等于里面样本的特征</span></span><br><span class="line">            reduceFeat = featVec[:axis]     <span class="comment"># 用reduceFeat补齐这个特征之前的所有特征</span></span><br><span class="line">            reduceFeat.extend(featVec[axis + <span class="number">1</span>:])       <span class="comment"># 补齐这个特征之后的所有特征</span></span><br><span class="line">            retData.append(reduceFeat)      <span class="comment"># 用retData来表示去掉这个特征的最终特征</span></span><br><span class="line"><span class="keyword">return</span> retData</span><br></pre></td></tr></table></figure>

<p>该函数为划分数据集函数，这里面用 reduceFeat 来存储去掉某个特征之后的数据集，然后返回该数据集用以迭代循环。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatSplit</span><span class="params">(data)</span>:</span></span><br><span class="line">    numFeats = len(data[<span class="number">0</span>]) - <span class="number">1</span>     <span class="comment"># 特征的数目，减去最后一个特征</span></span><br><span class="line">    bestGain = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeats):       <span class="comment"># i：0-3，在本例中只有4个特征</span></span><br><span class="line">        featlist = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> data]     <span class="comment"># 列表解析取出data中的一列数据</span></span><br><span class="line">        uniqueVals = set(featlist)          <span class="comment"># 转变为集合</span></span><br><span class="line">        newEntropy = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:            <span class="comment"># 遍历每个特征内所有集合的元素，对于i=0是，uniqueVals=&#123;summy,rainy,overcast&#125;</span></span><br><span class="line">            subData = splitData(data, i, value)      <span class="comment"># 对第一个特征中rainy划分数据集</span></span><br><span class="line">            prob = len(subData) / float(len(data))</span><br><span class="line">            newEntropy += prob * calcentropy(subData)   <span class="comment"># 求出条件熵</span></span><br><span class="line">        infoGain = baseGain - newEntropy                <span class="comment"># 计算信息增益</span></span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; bestGain:                         <span class="comment"># 取出最大的信息增益</span></span><br><span class="line">            bestGain = infoGain</span><br><span class="line">            bestfeat = i</span><br><span class="line"><span class="keyword">return</span> bestfeat                                     <span class="comment"># 返回当信息增益最大是的特征类别</span></span><br></pre></td></tr></table></figure>

<p>该函数是选择最佳的特征来分类，是整个步骤中最重要的一步，这里它用了一个列表解析取出数据集中某一列数据，然后转变为集合，通过比较每个类别的信息增益来返回最佳的特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creatTree</span><span class="params">(data, labels)</span>:</span></span><br><span class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> data]       <span class="comment"># 遍历数据集最后一列</span></span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):     <span class="comment"># 类别中的概率是否确定，即概率为1时，提前到达叶节点</span></span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]                             <span class="comment"># 返回该类别</span></span><br><span class="line">    <span class="keyword">if</span> len(data[<span class="number">0</span>]) == <span class="number">1</span>:       <span class="comment"># 是否只剩下一个类别，到达最终的叶节点</span></span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeature = chooseBestFeatSplit(data)         <span class="comment"># 选择最好的特征</span></span><br><span class="line">    bestFeatureLabel = labels[bestFeature]          <span class="comment"># 最好的特征表现</span></span><br><span class="line">    myTree = &#123;bestFeatureLabel:&#123;&#125;&#125;                  <span class="comment"># 创建树</span></span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeature])                        <span class="comment"># 删除已经计算过的特征</span></span><br><span class="line">    featValues = [example[bestFeature] <span class="keyword">for</span> example <span class="keyword">in</span> data]     <span class="comment"># 遍历根据最佳特征分割完成后的类别中的属性</span></span><br><span class="line">    uniqueVals = set(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        sublabels = labels[:]</span><br><span class="line">        myTree[bestFeatureLabel][value] = creatTree(splitData(data,bestFeature,value),sublabels)</span><br><span class="line"><span class="keyword">return</span> myTree</span><br></pre></td></tr></table></figure>

<p>该函数即为上图中决策树学习的基本算法，可以看到，它以 2 个条件做为迭代终止的条件，第一个是样本在类别中取值相同，这就说明已经到达了叶子节点，做出了最终决策，该阶段任务完成。第二个是只剩下一个类别时，迭代终止，到达最终的叶子节点。<br>以上程序为树的核心程序，剩下的用 matplot 绘图工具将生成的树绘出即可，程序如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    baseGain = calcentropy(dataSet)</span><br><span class="line">    myTree = creatTree(dataSet,labels)</span><br><span class="line">    print(myTree)</span><br></pre></td></tr></table></figure>

<p>最后运行结果出的决策树如下：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNDIxMDIyNzM1ND93YXRlcm1hcmsvMi90ZXh0L0x5OWliRzluTG1OelpHNHVibVYwTDNGeE9UQTBNekExTVRVNS9mb250LzVhNkw1TDJUL2ZvbnRzaXplLzQwMC9maWxsL0kwSkJRa0ZDTUE9PS9kaXNzb2x2ZS83MA?x-oss-process=image/format,png" alt="最终决策树图"></p>
<hr>
<h2 id="6-参考书目"><a href="#6-参考书目" class="headerlink" title="6 参考书目"></a>6 参考书目</h2><ul>
<li>机器学习 周志华</li>
<li>机器学习实战</li>
<li><a href="http://blog.csdn.net/c406495762/article/details/75663451" target="_blank" rel="noopener">Python3《机器学习实战》学习笔记（二）：决策树基础篇之让我们从相亲说起</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/turtlebot3%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8BUbuntu16-04%E4%B8%8ArealsenceR200%E7%9A%84%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/turtlebot3%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8BUbuntu16-04%E4%B8%8ArealsenceR200%E7%9A%84%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">turtlebot3（一）之Ubuntu16.04上realsenceR200的使用</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-30 22:48:08 / 修改时间：23:36:49" itemprop="dateCreated datePublished" datetime="2020-01-30T22:48:08+08:00">2020-01-30</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ROS/" itemprop="url" rel="index">
                    <span itemprop="name">ROS</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近实验室买了 turtlebot3，捣鼓了 1 个月，先是跑通了激光雷达 demo，现在又跑 realsenseR200 的 demo，现在将 realsense demo 的跑通过程记录下来。</p>
<hr>
<p><strong>设备：turtlebot3</strong><br><strong>平台：Ubuntu16.04.3</strong><br><strong>内核：4.4.14（17.12 月之前最新的内核）</strong></p>
<hr>
<p>安装过程主要参考了<a href="https://github.com/IntelRealSense/librealsense" target="_blank" rel="noopener">intel 的 github 项目</a>，在该网址上可以看到说明这个包适用于深度摄像机 D400 系列和 SR300，而实验室的摄像头信号是 R200，需要到另一个<a href="https://github.com/IntelRealSense/librealsense/tree/v1.12.1" target="_blank" rel="noopener">适用 R200 的网址</a>安装,如下所示:</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMjE4MjIxNTQxNjY1?x-oss-process=image/format,png" alt="适用R200的网址"></p>
<p>在这个网址安装时，由于当时使用<code>git clone</code>下载，后来发现下载的文件就是并非使用于 R200，所以建议直接下载 zip 文件，现在之后根据页面的安装手册，可以比较轻松的完成。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMjE4MjIxNjM1Njg1?x-oss-process=image/format,png" alt="linux的安装手册"></p>
<p>##3rd-party<br>首先，需要安装 3rd-party 依赖 1.保证 apt-get 的更新</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get upgrade</span><br></pre></td></tr></table></figure>

<p>2.安装<code>libusb-1.0</code>和<code>pkg-config</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libusb-1.0-0-dev pkg-config</span><br></pre></td></tr></table></figure>

<p>3.安装<code>glfw3</code>，Ubuntu14.04 需要用脚本安装（详见英文文档），Ubuntu16.04 可以直接用 apt-get 方式安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libglfw3-dev</span><br></pre></td></tr></table></figure>

<p>4.官方提供了 qt 和 cmake 来编译文件，这里选择使用 cmake 方式编译</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line">cd build</span><br></pre></td></tr></table></figure>

<p>这里将例程程序的编译也打开，方便安装完成后直接查看视频。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmake .. -DBUILD_EXAMPLES:BOOL&#x3D;true</span><br></pre></td></tr></table></figure>

<p>安装路径在<code>/usr/local/lib</code> ,头文件在<code>/usr/local/include</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make &amp;&amp; sudo make instal</span><br></pre></td></tr></table></figure>

<p>例程的执行程序在<code>build/examples</code>下</p>
<p>##Video4Linux backend 安装 1.确保<strong>没有摄像头</strong>插上系统，注意拔出所有摄像头。 2.安装<code>udve rules</code><br>返回源码目录，运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cp config&#x2F;99-realsense-libusb.rules &#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;</span><br><span class="line">sudo udevadm control --reload-rules &amp;&amp; udevadm trigger</span><br></pre></td></tr></table></figure>

<p>3.根据自己系统选择相应的方式选择安装版本。<br>由于我的系统是 Ubuntu16.04，内核为 4.4（<code>uname –a</code>命令查看系统和内核版本）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;scripts&#x2F;patch-uvcvideo-16.04.simple.sh</span><br></pre></td></tr></table></figure>

<p>这一步要经过漫长的安装。。。 4.重载 uvcvideo 驱动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo modprobe uvcvideo</span><br></pre></td></tr></table></figure>

<p>5.查看安装信息的最后 50 行，应该可以看到一个新的 uvcvideo 驱动被安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dmesg | tail -n 50</span><br></pre></td></tr></table></figure>

<p>运行后提示：（部分）</p>
<blockquote>
<p>Bluetooth: BNEP (Ethernet Emulation) ver 1.3<br>[ 34.033878] Bluetooth: BNEP filters: protocol multicast<br>[ 34.033885] Bluetooth: BNEP socket layer initialized<br>[ 39.136255] IPv6: ADDRCONF(NETDEV_UP): wlp1s0: link is not ready<br>[ 39.136424] iwlwifi 0000:01:00.0: L1 Disabled - LTR Disabled<br>[ 39.136685] iwlwifi 0000:01:00.0: L1 Disabled - LTR Disabled<br>[ 39.272219] iwlwifi 0000:01:00.0: L1 Disabled - LTR Disabled<br>[ 39.272483] iwlwifi 0000:01:00.0: L1 Disabled - LTR Disabled<br>[ 39.279661] mmc0: Got data interrupt 0x00000002 even though no data operation was in progress.<br>[ 39.341626] IPv6: ADDRCONF(NETDEV_UP): wlp1s0: link is not ready<br>[ 43.965760] IPv6: ADDRCONF(NETDEV_UP): wlp1s0: link is not ready<br>[ 48.638656] wlp1s0: authenticate with b0:95:8e:89:3a:0f<br>[ 48.640376] wlp1s0: send auth to b0:95:8e:89:3a:0f (try 1/3)<br>[ 48.756518] wlp1s0: send auth to b0:95:8e:89:3a:0f (try 2/3)<br>[ 48.758473] wlp1s0: authenticated<br>[ 48.761946] wlp1s0: associate with b0:95:8e:89:3a:0f (try 1/3)<br>[ 48.766951] wlp1s0: RX AssocResp from b0:95:8e:89:3a:0f (capab=0x431 status=0 aid=8)<br>[ 48.768057] wlp1s0: associated<br>[ 48.768117] IPv6: ADDRCONF(NETDEV_CHANGE): wlp1s0: link becomes ready<br>[ 49.063317] iwlwifi 0000:01:00.0: No association and the time event is over already…<br>[ 49.064030] wlp1s0: Connection to AP b0:95:8e:89:3a:0f lost<br>[ 64.507052] Bluetooth: RFCOMM TTY layer initialized<br>[ 64.507067] Bluetooth: RFCOMM socket layer initialized<br>[ 64.507076] Bluetooth: RFCOMM ver 1.11<br>[ 73.308219] wlp1s0: authenticate with b0:95:8e:89:3a:0f<br>[ 73.309839] wlp1s0: send auth to b0:95:8e:89:3a:0f (try 1/3)<br>[ 73.312326] wlp1s0: authenticated<br>[ 73.313219] wlp1s0: associate with b0:95:8e:89:3a:0f (try 1/3)<br>[ 73.319809] wlp1s0: RX AssocResp from b0:95:8e:89:3a:0f (capab=0x431 status=0 aid=8)<br>[ 73.321144] wlp1s0: associated<br>[ 75.552939] EXT4-fs (mmcblk1p3): recovery complete<br>[ 75.552950] EXT4-fs (mmcblk1p3): mounted filesystem with ordered data mode. Opts: (null)<br>[ 251.938597] media: Linux media interface: v0.10<br>[ 251.962588] Linux video capture interface: v2.00<br>[ 252.051084] usbcore: registered new interface driver uvcvideo<br>[ 252.051089] USB Video Class driver (1.1.1)</p>
</blockquote>
<p>到此为止，安装驱动过程已经全部完成，插上摄像头，运行 build/examples 下的文件即可看到效果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;cpp-capture</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMjE4MjIyMzQ2NTU1?x-oss-process=image/format,png" alt="截图1"></p>
<p>尝试运行其他程序得到相应的结果：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMjE4MjIyNDM3OTky?x-oss-process=image/format,png" alt="运行config-gui"></p>
<p>##遇到的问题<br>安装完成后，使用 PC 上的虚拟机远程连接 turtlebot3 运行例子并不管用，即使开启了使用虚拟机桌面的权限也没法运行起来，而且有时出现找不到设备的情况，然后当使用 turtlebot3 插上 mirco HDMI 线，使用显示屏开机时，发现一切正常，欣喜若狂啊，猜测它应该是要求系统加载桌面才能跑通 demo，因为即使说 turtlebot3 开机了，但是在开机的时候没有连接 HDMI 线，开机完成才连接，也没法完整运行例子程序，老是显示找不到设备。除此之外，turtlebor3 无缘无故”死机”的问题还没解决.</p>
<p>##思考<br>现在仅仅是实现了一个 demo，能否用它来实现一个小小的项目或者一些有意思的事情呢，目前因为对摄像头还不是很了解，也不知道其具体的应用方向，在想能否在 turtlebot3 上用它来实现 vslam，实现真正的自主导航！</p>
<p>##下一步<br>用 ROS 启动摄像头</p>
<p>##参考网站<br><a href="http://blog.csdn.net/bbqs1234/article/details/53912322" target="_blank" rel="noopener">CSDN blog</a><br><a href="https://github.com/IntelRealSense/librealsense/tree/v1.12.1" target="_blank" rel="noopener">intel github</a><br><a href="https://github.com/IntelRealSense/librealsense/blob/v1.12.1/doc/installation.md" target="_blank" rel="noopener">intel installation guide</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E7%8E%AF%E5%A2%83%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E7%8E%AF%E5%A2%83%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">深度学习服务器搭建环境记录</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-30 21:35:32" itemprop="dateCreated datePublished" datetime="2020-01-30T21:35:32+08:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-31 00:01:10" itemprop="dateModified" datetime="2020-01-31T00:01:10+08:00">2020-01-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><a href="#1-%e4%b8%8b%e8%bd%bd-anaconda">1. 下载 anaconda</a></li>
<li><a href="#2-%e9%85%8d%e7%bd%ae%e7%8e%af%e5%a2%83">2. 配置环境</a><ul>
<li><a href="#1-%e6%b7%bb%e5%8a%a0%e9%95%9c%e5%83%8f%e6%ba%90">1) 添加镜像源</a></li>
<li><a href="#2-%e5%88%9b%e5%bb%ba%e8%99%9a%e6%8b%9f%e7%8e%af%e5%a2%83">2) 创建虚拟环境</a></li>
<li><a href="#3%e5%ae%89%e8%a3%85-tensorflow-gpu">3）安装 tensorflow-GPU</a></li>
<li><a href="#4windows-%e4%b8%8a%e4%bd%bf%e7%94%a8%e6%9c%8d%e5%8a%a1%e5%99%a8%e4%b8%8a%e7%9a%84-jupyter-notebook">4）windows 上使用服务器上的 jupyter notebook</a></li>
<li><a href="#5%e5%9c%a8-windows-%e4%b8%8a%e4%bd%bf%e7%94%a8-vscode-%e5%90%8c%e6%ad%a5%e4%bb%a3%e7%a0%81%e5%88%b0-linux-%e4%b8%8a%e8%bf%90%e8%a1%8c">5）在 windows 上使用 vscode 同步代码到 Linux 上运行</a></li>
<li><a href="#6%e6%b5%8b%e8%af%95-gpu-%e6%98%af%e5%90%a6%e5%8f%af%e7%94%a8">6）测试 GPU 是否可用</a></li>
<li><a href="#7%e5%9c%a8%e6%9c%8d%e5%8a%a1%e5%99%a8%e4%b8%8a%e4%bd%bf%e7%94%a8%e5%90%8e%e5%8f%b0%e8%bf%90%e8%a1%8c%e4%bb%a3%e7%a0%81">7）在服务器上使用后台运行代码</a></li>
</ul>
</li>
<li><a href="#3-windows-%e4%b8%8e-linux-%e7%b3%bb%e7%bb%9f%e4%b9%8b%e9%97%b4%e7%9a%84%e6%96%87%e4%bb%b6%e4%ba%92%e7%9b%b8%e8%bd%ac%e7%a7%bb">3. windows 与 Linux 系统之间的文件互相转移</a></li>
</ul>
<h1 id="1-下载-anaconda"><a href="#1-下载-anaconda" class="headerlink" title="1. 下载 anaconda"></a>1. 下载 anaconda</h1><p>anaconda 的安装比较简单，参考<a href="https://docs.continuum.io/anaconda/install/linux.html" target="_blank" rel="noopener">官方文档的安装</a>即可，可以通过 Linux 下 wget 命令下载 anaconda 安装包，官网安装包下载比较慢，推荐使用<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">清华开源软件镜像站下载</a>，注意需要下载的版本要和 python 的版本对应，我想使用 python3.6，故而下载的是 anaconda5.2.0,当然，也可以下载最新的 anaconda 版本，再通过创建虚拟环境来安装想要的 python 版本都可以。<br>下载完直接使用<br><code>bash bash Anaconda3-5.2.0-Linux-x86_64.sh</code><br>命令安装即可，注意选择安装位置。</p>
<h1 id="2-配置环境"><a href="#2-配置环境" class="headerlink" title="2. 配置环境"></a>2. 配置环境</h1><h2 id="1-添加镜像源"><a href="#1-添加镜像源" class="headerlink" title="1) 添加镜像源"></a>1) 添加镜像源</h2><p>由于 anaconda 源在国外，访问速度可能很慢，可以添加清华镜像源，能够使下载安装包的速度大大提高。操作非常简单，在 anaconda prompt 中输入</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure>

<h2 id="2-创建虚拟环境"><a href="#2-创建虚拟环境" class="headerlink" title="2) 创建虚拟环境"></a>2) 创建虚拟环境</h2><p>可以通过网络搜索得到 anaconda 创建环境的命令为：<br><code>conda create --name env_zh python=3.6</code><br>也可以通过命令 conda -h 或 conda create -h 来查看 conda 自带的帮助手册，自带的帮助说明比网上搜索到的更加详细。还可以通过来<br>常用的命令如下<br><code>conda -h : anaconda</code>自带的帮助命令，很实用，网上搜索到的很多都不详细<br><code>conda create -h</code> 创建虚拟环境时的帮助命令，网上搜索不到时很有用<br><code>conda create --name env_zh --clone old_env</code>复制或克隆环境，可以复制已经搭建好的环境<br><code>conda env list</code>：查看现有的环境列表<br><code>conda-env remove -n test2</code> 删除 test2 虚拟环境<br><code>conda activate env_zh</code> 切换到 env_zh 虚拟环境<br><code>conda deactivate</code> 退出虚拟环境<br><code>conda serach tensorflow-gpu</code>搜索 tensorflow-GPU 的安装包，可以看到有多个版本的安装包</p>
<h2 id="3）安装-tensorflow-GPU"><a href="#3）安装-tensorflow-GPU" class="headerlink" title="3）安装 tensorflow-GPU"></a>3）安装 tensorflow-GPU</h2><p><code>conda install tensorflow-GPU=1.4</code>: 由于服务器上面已经安装了 CUDA，并且版本为 CUDA8，最高只支持<a href="https://tensorflow.google.cn/install/source" target="_blank" rel="noopener">tensorflow1.4</a>，如下图所示，1.4 版本的 tensorflowGPU 支持 3.6python 以及 6 版本的 cuDNN<br>除此之外，其他和 tensorflow 有关的常用命令如下：<br><code>cat /usr/local/cuda/version.txt</code> ： 查看 CUDA 版本的命令<br><code>cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</code> 查看 cudnn 版本命令<br><code>watch nvidia-smi</code> 实时查看当前 GPU 显存占用率</p>
<h2 id="4）windows-上使用服务器上的-jupyter-notebook"><a href="#4）windows-上使用服务器上的-jupyter-notebook" class="headerlink" title="4）windows 上使用服务器上的 jupyter notebook"></a>4）windows 上使用服务器上的 jupyter notebook</h2><p>在 windows 上使用 Linux 上的虚拟环境的 jupyter notebook<br>首先要保证在同一个局域网，Linux 上装好 anaconda，然后创建虚拟环境 env_zh,切换到虚拟环境<br><strong>第一种方法</strong></p>
<blockquote>
<p>安装牛逼 conda 包即可，<br><code>conda install nb_conda</code>，<br>安装完这个包，在当前环境下再次启动 jupyter notebook 就可以看到所有环境都显示出来了。</p>
</blockquote>
<p><strong>第二种方法</strong></p>
<blockquote>
<p>如果该方法不行，可以通过 jupyter 插件手动解决，激活环境或，安装 kpykernel<br><code>conda activate env_zh</code><br><code>conda install ipykernel</code><br><code>python -m ipykernel install --name env_zh --display-name python env_zh</code><br>启动之后根据提示给的网址在 windows 上登录即可，注意将 ip 地址改为服务器的 ip 地址即可。</p>
</blockquote>
<h2 id="5）在-windows-上使用-vscode-同步代码到-Linux-上运行"><a href="#5）在-windows-上使用-vscode-同步代码到-Linux-上运行" class="headerlink" title="5）在 windows 上使用 vscode 同步代码到 Linux 上运行"></a>5）在 windows 上使用 vscode 同步代码到 Linux 上运行</h2><p>参考<a href="https://code.visualstudio.com/docs/remote/remote-overview" target="_blank" rel="noopener">微软官方教程</a>，其实很简单，只需要在服务器上安装 ssh server，在 vscode 中安装远程开发包，然后通过 ip 地址远程连接就可以了。我没有去弄远程调试功能，因为比较麻烦，在服务器命令行中直接使用 python 运行就可以了。虽然官方教程显示远程开发环境搭建需要 Ubuntu16.04 及以上，但是我使用 Ubuntu14.04 也能够安装成功。</p>
<h2 id="6）测试-GPU-是否可用"><a href="#6）测试-GPU-是否可用" class="headerlink" title="6）测试 GPU 是否可用"></a>6）测试 GPU 是否可用</h2><p>在服务器上启动 jupyter server，在 windows 上登录网址，通过运行以下代码可以测试安装 GPU 版本的 tensorflow 是否成功</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<p>如果成功，会显示一个 CPU 和 GPU 的信息，我的是显示有 1 个 CPU 和两个 GPU。</p>
<h2 id="7）在服务器上使用后台运行代码"><a href="#7）在服务器上使用后台运行代码" class="headerlink" title="7）在服务器上使用后台运行代码"></a>7）在服务器上使用后台运行代码</h2><p>如果通过 putty 连接服务器来运行代码时，当连接断掉会自动停止，可以让代码在后台运行，这样就可以一直跑程序了。<br><a href="https://blog.csdn.net/sinat_28807899/article/details/89535005" target="_blank" rel="noopener">参考</a></p>
<h1 id="3-windows-与-Linux-系统之间的文件互相转移"><a href="#3-windows-与-Linux-系统之间的文件互相转移" class="headerlink" title="3. windows 与 Linux 系统之间的文件互相转移"></a>3. windows 与 Linux 系统之间的文件互相转移</h1><p>当在 Ubuntu 上搭建好了深度学习环境，有时数据集在 windows 上，如何将数据集转移到服务器上呢？用 U 盘比较麻烦，这里通过使用共享 windows 文件，然后在 Linux 上挂载文件就可以实现在 Linux 上访问 windows 文件夹的方法了。</p>
<blockquote>
<p>具体方法是，首先找到要共享的文件夹，在属性中添加共享，并开启网络发现，在一个局域网中，Linux 通过命令挂载登录到 windows 上的共享文件夹即可成功实现。</p>
<p>参考网上教程。</p>
</blockquote>
<p>环境搭建感悟：</p>
<ol>
<li><p>ensorflow 版本要和 cuda 和驱动版本对应，要不然无法正确使用 GPU，另外 tensorflow 有 GPU 版本，不能两个一起安装，否则会使用 CPU 版本的。</p>
</li>
<li><p>查看 GPU 使用情况 watch nvidia-smi</p>
</li>
<li><p>通过 jupyter notebook 可以远程写代码，通过 vscode 使用 ssh 可以远程调试和编辑 python 代码。</p>
</li>
<li><p>win10 挂载共享文件可以使在 Linux 上访问 Windows 文件夹。</p>
</li>
<li><p>充分使用 conda 的虚拟环境，可以省很多事情，有时候我们很多时候都把时间浪费到搭建环境中去了，都没有真正的关注深度学习这件事情本身。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chouzz.ml/2020/01/30/ResNet%E7%AC%94%E8%AE%B0-Deep-Residual-Learning-for-Image-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/myavatar.jpg">
      <meta itemprop="name" content="Chouzz">
      <meta itemprop="description" content="你只需努力，剩下的交给时间">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chouzz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/ResNet%E7%AC%94%E8%AE%B0-Deep-Residual-Learning-for-Image-Recognition/" class="post-title-link" itemprop="url">ResNet笔记(Deep Residual Learning for Image Recognition)</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-30 20:28:34 / 修改时间：21:17:58" itemprop="dateCreated datePublished" datetime="2020-01-30T20:28:34+08:00">2020-01-30</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><a href="#resnetdeep-residual-learning-for-image-recognition">ResNet(Deep Residual Learning for Image Recognition)</a><ul>
<li><a href="#%e6%a6%82%e8%bf%b0">概述</a></li>
<li><a href="#%e9%97%ae%e9%a2%98%e7%9a%84%e6%8f%90%e5%87%ba">问题的提出</a></li>
<li><a href="#%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84">网络结构</a></li>
<li><a href="#%e5%ae%9e%e6%96%bd%e7%bb%86%e8%8a%82">实施细节</a></li>
</ul>
</li>
</ul>
<h1 id="ResNet-Deep-Residual-Learning-for-Image-Recognition"><a href="#ResNet-Deep-Residual-Learning-for-Image-Recognition" class="headerlink" title="ResNet(Deep Residual Learning for Image Recognition)"></a>ResNet(Deep Residual Learning for Image Recognition)</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>2015 年，由微软亚洲研究院何凯明等人发表的 ResNet 网络，成功的将网络层数加到更深的层次，并且获得了很好的效果，其复杂度也与之前的 vgg 网络相差不大，并且获得到了 ILSVRC 2015 和 COCO 2015 的分类任务竞赛冠军，同样也在 CIFAR-10 数据集上进行了 100 到 1000 层的测试。</p>
<h2 id="问题的提出"><a href="#问题的提出" class="headerlink" title="问题的提出"></a>问题的提出</h2><center>   
<img src="https://img-blog.csdnimg.cn/20191220145354299.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="深层网络误差更大的现象" width="80%" height="80%">    

<p>Fig.1 深层网络误差更大的现象</p>
</center>

<hr>
<p>是否越深的网络学习的就会更好？如上图所示，作者在 CIFAR-10 数据集上进行实验，发现 56 层的网络无论是在训练误差还是在测试误差上效果都比 20 层网络的效果差，这说明并不是越深的网络效果就会越好，因为深层网络带来梯度消失或者爆炸问题，导致深层网络的误差加大，一些现在已有的常用的方法是使用正则化初始化和中间初始化来解决，而当随着网络层数的加深，精度达到饱和的时候，继续进行训练精度反而快速下降，这种现象并不是因为过拟合导致的，论文给出猜想，添加一层额外的恒等映射，如下图所示：</p>
<center>
<img src="https://img-blog.csdnimg.cn/20191222194635612.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="ResNet提出的剩余/残差学习模块" width="60%" height="60%">     

<p>Fig.2 ResNet 提出的剩余/残差学习模块</p>
</center>

<hr>
<p>这就是论文一开始提出 ResNet 模块，论文中提到了还有很多和短连接相关的工作，这里的短连接就是恒等映射，然后将输出加上叠层网络，最后输出的就是$F(x)+x$了。<br>然后提出了 ResNet 有 2 个优点：</p>
<ol>
<li>容易优化，其他建档叠加网络层数有很大的训练误差，也就是下图中所表现的 20 层和 56 层的训练误差</li>
<li>比之前的网络如 vgg 能够获得更高的精度</li>
</ol>
<p>作者使用该网络效果比 vgg 好，在 ImageNet 中误差率低，并在 ILSVRC2015 和 ImageNet 检测，定位和 COCO 分割竞赛中都获得了第一名，说明该网路确实是有很好的效果的。</p>
<hr>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>论文中提出了 2 种网络结构，一种是 plain 也就是原始的网络，另外一种是加上剩余学习或者叫做残差模块的残差网络，他们的网络结构如下表：<br>![在这里插入图片描述])</p>
<center>
<img src="https://img-blog.csdnimg.cn/20191222194733313.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="vgg19，plain34和ResNet34网络结构" width="60%" height="60%">

<p>Fig.3 ResNet 提出的剩余/残差学习模块</p>
</center>

<hr>
<p>从左到右依次是 vgg19，plain，和 resnet，每种网络都包含了 4 个模块，经过每个模块的池化之后，分别缩小到原图的 1/2, 1/4, 1/8, 1/16 大小,每个模块都包含不同数量的卷积层数，而 34 层的 ResNet 特殊的一点就是加入了短连接，也就是图中曲线部分。</p>
<p>plain 网络的想法来自于 vggnet，卷积层大多使用 3x3 的滤波器，然后遵循两条规则：</p>
<ol>
<li>对输出相同的特征图大小，网络有相同数量的滤波器</li>
<li>如果特征图大小减半，滤波器数量加倍来保留每层网络的时间复杂度(这样为何可以保留时间复杂度？？)</li>
</ol>
<h2 id="实施细节"><a href="#实施细节" class="headerlink" title="实施细节"></a>实施细节</h2><p>在 ImageNet 上的实现细节是跟着 vgg 论文来的。</p>
<ul>
<li>数据增强： random crop 224x224, horizontal flip,per-pixel mean subtracted，标准色彩增强(standard color augmentation)</li>
<li>在卷积层激活函数层之间添加 BatchNormalization</li>
<li>初始化权重(来自于：Delving deep into rectifers: Surpassing human-level performance on imagenet classifcation)</li>
<li>优化器: SGD</li>
<li>mini-batch: 256</li>
<li>learning rate: 从 0.1 开始当误差停止时减小 10 倍</li>
<li>迭代次数：600K, 迭代次数太多啦。。。</li>
<li>weight decay: 0.0001</li>
<li>momentum: 0.9</li>
<li>没有用到 dropout</li>
</ul>
<p>下图中左侧为 18 层和 34 层的 plain 网络的训练和验证误差，这里就有了退化问题，即 34 层的网络比 18 层网络的误差率更高，作者明确说明这种优化困难不是梯度消失造成的，因为 plain 网络已经使用 BN 进行了训练，确保了网络前向传播信号具有非 0 的方差，作者推测这是因为网络收敛速度极低，影响到了训练误差。<br>而下图中右侧为 18 层和 34 层的 ResNet 的训练和验证误差，作者提到从该图中可以观测到 3 点：</p>
<ol>
<li>残差学习可以扭转这种局面，34 层网络比 18 层网络误差更小，比 plain 网络有明显的区别，而且 34 层 ResNet 在验证数据上更好，表明 ResNet 可以很好的解决退化问题。</li>
<li>和 plain 的 34 层网络相比，ResNet34 获得了更小的训练误差，表明了残差系统可以在极深的系统中学习</li>
<li>和 palin 的 18 层网络相比，ResNet18 学习的更好，这说明了当网络没有那么深的时候(这里是 18 层),当前的 SGD 优化器仍然可以找到很好的解决方案，在这种情况下，ResNet 通过更快的收敛来简化优化。</li>
</ol>
<center>
<img src="https://img-blog.csdnimg.cn/2019122219483963.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="Plain和ResNet网络在ImageNet上的训练和验证误差" width="80%" height="80%">
<center>
Fig.4 Plain 和 ResNet 网络在 ImageNet 上的训练和验证误差

</center>

<hr>
<p>ImageNet 中的结果，误差率如下图：</p>
<center>
<img src="https://img-blog.csdnimg.cn/20191222195004223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="plain和ResNet在ImageNet中的误差率" width="60%" height="60%">
<center>
Fig.5 plain 和 ResNet 在 ImageNet 中的误差率

</center>

<hr>
<p>到此为止已经说明了 ResNet 的优势所在了，作者又提出了另一种 ResNet 模块，Bottleneck ResNet，和之前的 buildingResNet 一样，只不过多增加了一层卷积层，该模块用于 ResNet-50/101/152,如下图所示：</p>
<center>
<img src="https://img-blog.csdnimg.cn/20191222195042697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="Building ResNet和Bottleneck ResNet" width="60%" height="60%">
<center>
Fig.6 Building ResNet 和 Bottleneck ResNet

</center>

<hr>
<p>其中的 ResNet101 和 ResNet152 具体网络结构如下图所示：</p>
<center>
<img src="https://img-blog.csdnimg.cn/20191222195115172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxOTA0MzA1MTU5,size_16,color_FFFFFF,t_70" alt="ResNet在ImageNet上的具体网络架构" width="60%" height="60%">
<center>
Fig.7 ResNet 在 ImageNet 上的具体网络架构

</center>
</center></center></center></center>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chouzz"
      src="/images/myavatar.jpg">
  <p class="site-author-name" itemprop="name">Chouzz</p>
  <div class="site-description" itemprop="description">你只需努力，剩下的交给时间</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/chouzz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chouzz" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhouhua25@qq.com" title="E-Mail → mailto:zhouhua25@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chouzz</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  















  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
